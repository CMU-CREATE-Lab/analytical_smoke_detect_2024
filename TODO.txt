(Also see TODO_VIDEO_EXPORT.txt)

Version 0.3
HH: Download sequence of images via thumbnail_api
HH: Try time-series / video.  Can we do patches for video?
    What size patch seems good?
        8x8x8 = 512 pixels  - small discrepencies
        16x16x16
HH: Try zoomed out video
HH: Try images of increased size

RS: Be able to see opacity with single frame (numpy ndarray) or multiple frames in sequence (3d array)
  Maybe use textured background, or bright green?
  Maybe show opacity map (alpha channel) with colors and/or contours?
  Maybe also show color of smoke with alpha=1?
RS: How much CPU time is used per process?
DONE Parallelize v2 patchwise

BACKLOG:
What subsampling is happening?  Is it nearest neighbor (ugh) or actually low-pass filtering in some way?
See how parallelized v2 scales to larger images
If full least-squares minimization is too slow to search entire days at full res, consider:
  subsample in space and/or time
  simpler difference search as preprocessor before handing only changes to least sq


DONE Version 0.2
DONE Display CPU time for v2 (single)
DONE Reduce logging for v2 (patches)
DONE Use sparse least squares to detect haze locally (i.e. in patches)
DONE Combine patches to get a global haze map
DONE Commit

DONE Version 0.1
DONE Uses sparse least squares to detect haze in an entire image at once

